{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bef891dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, concatenate, Dense, SpatialDropout1D, Bidirectional, Dropout\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f73f050",
   "metadata": {},
   "source": [
    "# 1) Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c53c78c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_data.csv')\n",
    "test_df = pd.read_csv('test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cdac7fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features\n",
    "features = ['num_sentences', 'misspelling_percentage', 'pos_verbs_percentage',\n",
    "             'spaces_percentage', 'sentiment_score', 'money_score', 'payment_score',\n",
    "             'celebration_score', 'achievement_score', 'url_presence',\n",
    "             'phone_number_presence']\n",
    "\n",
    "train_text_data = train_df['cleaned_text'].astype(str)\n",
    "train_numerical_features = train_df[features].values\n",
    "train_labels = train_df['binary_label']\n",
    "\n",
    "test_text_data = test_df['cleaned_text'].astype(str)\n",
    "test_numerical_features = test_df[features].values\n",
    "test_labels = test_df['binary_label']\n",
    "\n",
    "# Text data preprocessing\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_text_data)\n",
    "X_train_text = tokenizer.texts_to_sequences(train_text_data)\n",
    "X_test_text = tokenizer.texts_to_sequences(test_text_data)\n",
    "max_length = 200 # majority of sequences have less than 200 tokens\n",
    "X_train_text = pad_sequences(X_train_text, maxlen=max_length)\n",
    "X_test_text = pad_sequences(X_test_text, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5c1d39",
   "metadata": {},
   "source": [
    "# 2) Model architecture\n",
    "\n",
    "1. **Embedding Layer**:\n",
    "   - Converts integer-encoded tokens into dense vectors of fixed size.\n",
    "   - Each token is mapped to a unique vector in a high-dimensional space.\n",
    "   - Captures semantic relationships between words based on their context.\n",
    "\n",
    "\n",
    "2. **Spatial Dropout Layer**:\n",
    "   - Applies dropout regularization specifically designed for 1D input data (e.g., sequences).\n",
    "   - Randomly sets a fraction of input units to zero during training to prevent overfitting.\n",
    "\n",
    "\n",
    "3. **Bidirectional LSTM Layer**:\n",
    "   - Consists of forward and backward LSTM units, allowing it to capture information from both past and future context.\n",
    "   - Each LSTM unit maintains an internal state and processes the input sequence step by step, updating its state at each time step.\n",
    "\n",
    "\n",
    "5. **Concatenation Layer**:\n",
    "   - Combines the outputs of the LSTM layer (both forward and backward representations) with the numerical features.\n",
    "\n",
    "\n",
    "6. **Dropout Layer**:\n",
    "   - Applies dropout regularization to the concatenated features.\n",
    "   - Randomly sets a fraction of input units to zero during training to prevent overfitting.\n",
    "\n",
    "\n",
    "7. **Dense Output Layer**:\n",
    "   - A fully connected layer that produces the final output predictions.\n",
    "   - Uses a sigmoid activation function to output a probability score for binary classification tasks.\n",
    "   - Output value close to 1 indicates a positive prediction, while a value close to 0 indicates a negative prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d5f5aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model architecture\n",
    "text_input = Input(shape=(max_length,), name='text_input')\n",
    "numerical_input = Input(shape=(len(features),), name='numerical_input')\n",
    "embedding_layer = Embedding(len(tokenizer.word_index) + 1, 128, input_length=max_length)(text_input)\n",
    "spatial_dropout = SpatialDropout1D(0.2)(embedding_layer)\n",
    "lstm_layer = Bidirectional(LSTM(64, dropout=0.2, recurrent_dropout=0.2))(spatial_dropout)\n",
    "concatenated = concatenate([lstm_layer, numerical_input])\n",
    "dropout_layer = Dropout(0.2)(concatenated)\n",
    "output = Dense(1, activation='sigmoid')(dropout_layer)\n",
    "model = Model(inputs=[text_input, numerical_input], outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Callback\n",
    "checkpoint_filepath = 'best_lstm.h5'\n",
    "checkpoint_callback = ModelCheckpoint(filepath=checkpoint_filepath,\n",
    "                                      monitor='val_loss',\n",
    "                                      save_best_only=True,\n",
    "                                      mode='min',\n",
    "                                      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3cb0638f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1188/1188 [==============================] - 1960s 2s/step - loss: 0.1370 - accuracy: 0.9505 - val_loss: 0.1055 - val_accuracy: 0.9596\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10546, saving model to best_lstm.h5\n",
      "Epoch 2/10\n",
      "1188/1188 [==============================] - 1752s 1s/step - loss: 0.0543 - accuracy: 0.9808 - val_loss: 0.0914 - val_accuracy: 0.9674\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.10546 to 0.09136, saving model to best_lstm.h5\n",
      "Epoch 3/10\n",
      "1188/1188 [==============================] - 1630s 1s/step - loss: 0.0212 - accuracy: 0.9933 - val_loss: 0.0972 - val_accuracy: 0.9701\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.09136\n",
      "Epoch 4/10\n",
      "1188/1188 [==============================] - 1739s 1s/step - loss: 0.0267 - accuracy: 0.9909 - val_loss: 0.1272 - val_accuracy: 0.9620\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.09136\n",
      "Epoch 5/10\n",
      "1188/1188 [==============================] - 1673s 1s/step - loss: 0.0153 - accuracy: 0.9956 - val_loss: 0.1154 - val_accuracy: 0.9647\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.09136\n",
      "Epoch 6/10\n",
      "1188/1188 [==============================] - 1860s 2s/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.1448 - val_accuracy: 0.9675\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.09136\n",
      "Epoch 7/10\n",
      "1188/1188 [==============================] - 1843s 2s/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.1619 - val_accuracy: 0.9568\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.09136\n",
      "Epoch 8/10\n",
      "1188/1188 [==============================] - 2166s 2s/step - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.1483 - val_accuracy: 0.9681\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.09136\n",
      "Epoch 9/10\n",
      "1188/1188 [==============================] - 2915s 2s/step - loss: 0.0090 - accuracy: 0.9973 - val_loss: 0.1548 - val_accuracy: 0.9637\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.09136\n",
      "Epoch 10/10\n",
      "1188/1188 [==============================] - 3401s 3s/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 0.1777 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.09136\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x188a84bdbb0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([X_train_text, train_numerical_features], train_labels, \n",
    "          epochs=10, batch_size=32, validation_split=0.2,\n",
    "          callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef7e341",
   "metadata": {},
   "source": [
    "# 3) Model Evaluation\n",
    "The best model is saved from epoch 2 where `val_loss` was lowest. We need to convert the output into binary predictions before doing the classfication report. We find that the model is performing well enough even for the minority `spam` class. Hence we will not proceed with hyperparameter tuning or changing the model architecture due to computational constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f63633c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97      7169\n",
      "           1       0.96      0.96      0.96      4704\n",
      "\n",
      "    accuracy                           0.97     11873\n",
      "   macro avg       0.97      0.97      0.97     11873\n",
      "weighted avg       0.97      0.97      0.97     11873\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict labels for test data\n",
    "best_model = load_model(checkpoint_filepath)\n",
    "\n",
    "y_pred = best_model.predict([X_test_text, test_numerical_features])\n",
    "y_pred = (y_pred > 0.5).astype(int)  # Convert probabilities to binary predictions\n",
    "\n",
    "# Convert labels to binary values (0 or 1)\n",
    "test_labels_binary = (test_labels > 0.5).astype(int)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(test_labels_binary, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64043ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
